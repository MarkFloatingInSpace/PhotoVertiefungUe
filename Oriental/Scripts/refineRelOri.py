# -*- coding: cp1252 -*-
"""
Having oriented a new photo, relOri currently only considers pairwise matches unfortunately.
If the intersection angle in an objPt is too small, then that objPt will not be triangulated.
This means that image observations known to sfm.featureTracks,
but unknown to sfm.edge2matches will not be introduced. For highly overlapping imagery,
this makes the reconstruction less stable than it could be.
refineRelOri takes the image orientations from relOri and introduces all image observations known to sfm.featureTracks,
which must have been pickled by relOri.
"""
import pickle
from collections import namedtuple, Counter
from pathlib import Path
from itertools import chain, count
from functools import partial, wraps
from contextlib import contextmanager, suppress, ExitStack
import os
import time
import struct

from contracts import contract, new_contract
from sqlite3 import dbapi2
import h5py
import numpy as np
from scipy import linalg, spatial
import matplotlib.pyplot as plt
from mpl_toolkits.axes_grid1.anchored_artists import AnchoredSizeBar
import cv2

from oriental import adjust, ori, log, Progress, utils
from oriental.adjust.parameters import ADP
from oriental.adjust.local_parameterization import Subset
from oriental.utils.db import uri4sqlite, initDataBase, createUpdateSchema
import oriental.utils.filePaths

logger = log.Logger("refineRelOri")
new_contract('Path',Path)

Image = namedtuple('Image','id path prc omfika nRows nCols camera') # nRows,nCols nach Camera verschieben?
ImageWKeyPts = namedtuple('ImageWKeyPts', Image._fields + ('keypts',))
Camera = namedtuple('Camera',['id','ior','s_ior','adp','s_adp'])
#ImgObs = namedtuple('ImgObs',['iImg','iKeyPt','resId'])
ObjPt = namedtuple('ObjPt',['arr','obs']) # obs: { imgId : residualBlockId }
# Schwächen an dieser Datenorganisation: es ist ein wenig aufwändig, z.B. pro pho die von den aktiven Bildbeobachtungen bedeckte Bildfläche zu berechnen
# es ist recht aufwändig, die Residuen für eine bestimmte Kamera zu berechnen (Verzeichnungsplot).

projDir = Path(r'D:\MilutinPielach')
os.chdir( str(relOriDir / 'relOriRefine') )
relOriDir = projDir / 'relOri'
featureTracksPickle = relOriDir / 'featureTracks.pickle'
featuresFn          = relOriDir / 'features.h5'
relOriDbFn          = relOriDir / 'relOri.sqlite'

@contextmanager
def progressAfter(progress):
    yield
    progress += 1

def export(block,images,objPts,fn):
    #nObjPts = len(objPts)
    plyFn = '{}.ply'.format(fn)
    with open( plyFn, 'wb' ) as fout:
        fout.write("""ply
format binary_little_endian 1.0
comment generated by OrientAL
element vertex {nVertices}
property float64 x
property float64 y
property float64 z
property uint8 red
property uint8 green
property uint8 blue
property uint8 nImgPts
element face {nFaces}
property list uint8 uint32 vertex_indices
end_header
""".format( nVertices=len(objPts) + len(images)*(5+8*3), nFaces=len(images)*(6+6*2*3) ).encode('ascii') )
        stru = struct.Struct('<dddBBBB')
        for objPt in objPts.values():
            rbg = np.median( [ block.GetCostFunctionForResidualBlock(resId).data for resId in objPt.obs.values() ], axis=0 )
            fout.write( stru.pack( *chain( objPt.arr, (rbg*255).astype(np.uint8), [len(objPt.obs)] ) )  )

        prcs = np.array([image.prc for image in images.values()])
        tree = spatial.cKDTree(prcs)
        dists, indxs = tree.query(prcs, k=2, n_jobs=-1)
        medMinimumInterPrcDist = np.median( dists[:,1] )

        for image in images.values():
            pts = np.array([ [            0,             0,          0  ],
                             [  image.nCols/2,  image.nRows/2, -image.camera.ior[2] ],
                             [ -image.nCols/2,  image.nRows/2, -image.camera.ior[2] ],
                             [ -image.nCols/2, -image.nRows/2, -image.camera.ior[2] ],
                             [  image.nCols/2, -image.nRows/2, -image.camera.ior[2] ] ], float)
            # scale pyramids
            scale = medMinimumInterPrcDist / 2 / image.camera.ior[2]
            pts *= scale
            R = ori.omfika( image.omfika )
            pts = R.dot( pts.T ).T + image.prc
            for pt in pts:
                fout.write( stru.pack( *chain( pt, np.array([255,0,255],dtype=np.uint8), [0] ) ) )
                    
            # axes as cuboids
            axLen = ( image.nCols + image.nRows ) / 4.
            axWid = axLen / 20.
            pts = np.array([ [ 0.,  axWid,  axWid ],
                             [ 0., -axWid,  axWid ],
                             [ 0., -axWid, -axWid ],
                             [ 0.,  axWid, -axWid ] ] )
            pts = np.r_[ pts, pts + np.array([ axLen, 0., 0. ]) ] * scale
            for iAx in range(3):
                if iAx==0:
                    R2 = np.eye(3)
                elif iAx==1:
                    R2 = np.array([[  0, 1, 0 ],
                                   [ -1, 0, 0 ],
                                   [  0, 0, 1 ]],float).T
                else:
                    R2 = np.array([[  0, 0, 1 ],
                                   [  0, 1, 0 ],
                                   [ -1, 0, 0 ]],float).T
                pts_ = R.dot(R2).dot( pts.T ).T + image.prc
                for pt in pts_:
                    fout.write( stru.pack( *chain( pt, np.array([255,0,255],dtype=np.uint8), [0] ) ) )

        stru = struct.Struct('<BIII')
        for idx,image in enumerate(images.values()):
            # CloudCompare does not support:
            # - reading polylines from PLY files
            # - faces with a vertex count other than 3                          
            offset = len(objPts) + idx * (5+8*3)
            for iVtxs in np.array([[0, 1, 2],
                                   [0, 2, 3],
                                   [0, 3, 4],
                                   [0, 4, 1],
                                   [1, 2, 3],
                                   [3, 4, 1]], int):
                fout.write( stru.pack( *chain( [3], iVtxs+offset ) ) )
            for iAx in range(3):
                offset = len(objPts) + idx * (5+8*3) + 5 + 8*iAx
                for iVtxs in np.array([[0, 3, 2],
                                       [2, 1, 0],
                                       [0, 1, 5],
                                       [5, 4, 0],
                                       [0, 4, 7],
                                       [7, 3, 0],
                                       [2, 3, 7],
                                       [7, 6, 2],
                                       [1, 2, 6],
                                       [6, 5, 1],
                                       [4, 5, 6],
                                       [6, 7, 4]], int):
                    fout.write( stru.pack( *chain( [3], iVtxs+offset ) ) )
    logger.info( 'Reconstruction exported to "{}"', plyFn )

def saveSQLite( cameras, images, objPts, block, resultsFn ):
    with suppress(OSError):
        os.remove(resultsFn)

    createUpdateSchema( resultsFn )

    conn = dbapi2.connect( resultsFn )

    initDataBase( conn )
    
    conn.execute( """
        CREATE TABLE config( id INTEGER NOT NULL PRIMARY KEY AUTOINCREMENT,
                                name NOT NULL,
                                value )""" )
        
    conn.execute( """
        SELECT AddGeometryColumn(
            'objpts', -- table
            'pt',     -- column
            -1,       -- srid -1: undefined/local cartesian cooSys
            'POINT',  -- geom_type
            'XYZ',    -- dimension
            1         -- NOT NULL
        )""" )
            

    with conn:  
            
        pointZWkb = struct.Struct('<bIddd')
        def packPointZ(pt):
            # 1001 is the code for points with z-coordinate
            # Must wrap the str returned by struct.pack(.) into a memoryview object, or otherwise, SQLite complains about receiving 8-bit-strings instead of unicode. However, we want the string to be interpreted byte-wise.
            # Even though buffer is deprecated since Python 2.7, there is no other way to pass the data: http://bugs.python.org/issue7723
            # For Python 3, SQLite accepts bytes/memoryview and returns bytes for BLOBs!
            return pointZWkb.pack( 1, 1001, *pt )

        conn.executemany( """INSERT INTO objpts(id,pt) VALUES( ?, GeomFromWKB(?, -1) )""",
                            ( ( iPt, packPointZ(pt.arr) )
                            for iPt,pt in objPts.items() ) )
            
        photoDistortionValuesEnums = sorted( adjust.PhotoDistortion.values.items(), key=lambda x: x[0] )
        insertCameras =   "INSERT INTO cameras(id, make, model, isDigital, x0, y0, z0, s_x0, s_y0, s_z0, reference, normalizationRadius," \
                        + ','.join(   [        str(val[1]) for val in photoDistortionValuesEnums ]
                                    + [ 's_' + str(val[1]) for val in photoDistortionValuesEnums ] ) \
                        + ')\n' \
                        + 'VALUES( ' + ','.join( '?' * (6 + 3*2 + 9*2) ) +  ' )'

        for camId,camera in cameras.items():
            stdDevsIorAdp = []
            for parBlock in (camera.ior,camera.adp):
                if block.IsParameterBlockConstant( parBlock ):
                    stdDevs = np.zeros( parBlock.size )
                else:
                    locParam = block.GetParameterization( parBlock )
                    if locParam is None:
                        stdDevs = np.full( parBlock.size, np.nan )
                    else:
                        stdDevs = np.array([ (0.0 if locParam.isConstant(idx) else None) for idx in range(parBlock.size) ], dtype=np.float )
                stdDevsIorAdp.append( stdDevs )

            conn.execute( insertCameras,
                          tuple( chain(
                              ( camId, 'Sony', 'ILCE-6000', True ),
                              camera.ior,
                              stdDevsIorAdp[0],
                              ( str(adjust.AdpReferencePoint.principalPoint),
                                camera.adp.normalizationRadius ),
                              camera.adp,
                             stdDevsIorAdp[1] ) )
                        )
               
        def genImages():
            for imgId,image in images.items():
                yield tuple( chain(
                    ( imgId,
                      image.camera.id,
                      str( utils.filePaths.relPathIfExists( image.path, os.path.dirname(resultsFn) ) ),
                      image.nCols,
                      image.nRows ),
                    image.prc,
                    image.omfika ) )

        conn.executemany( """INSERT INTO images( id, camID, path, nCols, nRows, X0, Y0, Z0, r1, r2, r3, parameterization )
                                         VALUES(  ?,     ?,    ?,     ?,     ?,  ?,  ?,  ?,  ?,  ?,  ?, 'omfika' )""",
                            genImages() )


        pointWkb = struct.Struct('<bIdd')
        def packPoint(pt):
            # 1 is the code for 2D points
            return pointWkb.pack( 1, 1, *pt )
            
        def getImgPts():
            for objPtId,objPt in objPts.items():
                for imgId,resId in objPt.obs.items():
                    cost = block.GetCostFunctionForResidualBlock( resId )
                    yield ( imgId, objPtId, objPtId, cost.x, cost.y, cost.data[0], cost.data[1], cost.data[2] )
        
        conn.executemany( """INSERT INTO imgobs( imgID, name, objPtID, x, y, red, green, blue )
                                         VALUES(     ?,    ?,       ?, ?, ?,   ?,     ?,    ? )""",
                            getImgPts() )

        
    conn.execute( "CREATE INDEX idx_images_camid ON images(camid)" )

    conn.execute( "CREATE INDEX idx_imgobs_objPtID ON imgobs(objPtID)" )
       
    conn.execute("ANALYZE")
                                           
    logger.info("Results stored in SpatiaLite DB '{}'".format(resultsFn))   

@contract
def restoreRelOriImages( relOriDbFn : Path ):
    cameras = {}
    images = {}
    with dbapi2.connect( uri4sqlite(relOriDbFn) + '?mode=ro', uri=True ) as relOriDb:
        initDataBase(relOriDb)

        photoDistortionValuesEnums = sorted( adjust.PhotoDistortion.values.items(), key=lambda x: x[0] )
        rows = relOriDb.execute("""
            SELECT id, x0, y0, z0, s_x0, s_y0, s_z0,
                   reference, normalizationRadius, {}, {}
            FROM cameras """.format(
                ', '.join((           str(val[1]) for val in photoDistortionValuesEnums )),
                ', '.join(( 's_{}'.format(val[1]) for val in photoDistortionValuesEnums )) ) )
        for row in rows:
            v_adp = []
            s_adp = []
            for val,enumerator in photoDistortionValuesEnums:
                v_adp.append( row[str(enumerator)] )
                s_adp.append( row['s_{}'.format(str(enumerator))] )
            adp = ADP( normalizationRadius=row['normalizationRadius'],
                       referencePoint     = adjust.AdpReferencePoint.names[ row['reference'] ],
                       array              = np.array(v_adp) )
            cameras[row['id']] = Camera( row['id'],
                                         np.array([ row['x0']  , row['y0']  , row['z0']  ]),
                                         np.array([ row['s_x0'], row['s_y0'], row['s_z0']], float),
                                         adp,
                                         np.array(s_adp, float ) )

        for row in relOriDb.execute("""
            SELECT id, camId, path, X0, Y0, Z0, r1, r2, r3, parameterization, nRows, nCols
            FROM images """ ):
            assert row['parameterization'] == 'omfika'
            path = Path( row['path'] )
            if not path.is_absolute():
                path = relOriDbFn.parent / path
            path = path.resolve()
            images[row['id']] = Image( row['id'],
                                       path,
                                       np.array([ row['X0'], row['Y0'], row['Z0'] ]),
                                       np.array([ row['r1'], row['r2'], row['r3'] ]),
                                       row['nRows'],
                                       row['nCols'],
                                       cameras[row['camId']] )

    return cameras, images

def robustLoss( arg ):
    return adjust.loss.Arctan(arg)

def timed( func ):
    @wraps(func)
    def wrapper(*args,**kwargs):
        start = time.clock()
        res = func(*args,**kwargs)
        logger.info( 'Function {} took {:.1f}s', func.__name__, time.clock() - start )
        return res
    return wrapper

class TriFailed(Exception):
    pass

def triangulate( imagesAndObs, robLossGen ):
    if len(imagesAndObs) < 2:
        raise Exception('Cannot triangulate a point with less than 2 image observations')
    if 0:
        X = np.array([ 0., 0., -50. ])
    else:
        pts = []
        for image,*_ in imagesAndObs:
            R = ori.omfika(image.omfika)
            pt = np.array([0.,0.,-1])
            pts.append( R.dot(pt) + image.prc )
        X = np.median(pts, axis=0)

    problem = adjust.Problem()
    loss = robLossGen()
    for image,x,y,*_ in imagesAndObs:
        cost = adjust.cost.PhotoTorlegard( x, y )
        problem.AddResidualBlock( cost,
                                  loss,
                                  image.prc,
                                  image.omfika,
                                  image.camera.ior,
                                  image.camera.adp,
                                  X )
        for par in ( image.prc, image.omfika, image.camera.ior, image.camera.adp ):
            problem.SetParameterBlockConstant( par )
    solveOpts = adjust.Solver.Options()
    solveOpts.linear_solver_type = adjust.LinearSolverType.DENSE_QR
    solveOpts.max_num_iterations = 50
    solveOpts.function_tolerance = 1.e-13
    solveOpts.gradient_tolerance = 1.e-13
    solveOpts.parameter_tolerance = 1.e-13
    summary = adjust.Solver.Summary()
    adjust.Solve(solveOpts, problem, summary)
    if not adjust.isSuccess( summary.termination_type ) or \
        summary.num_successful_steps == 0:
        raise TriFailed()
    evalOpts = adjust.Problem.EvaluateOptions()
    evalOpts.apply_loss_function = False
    residuals, = problem.Evaluate( evalOpts )
    resNormsSqr = residuals[0::2]**2 + residuals[1::2]**2
    return X, resNormsSqr

cameras, images = restoreRelOriImages( relOriDbFn )

imageBaseFn2Id = { value.path.name : key for key,value in images.items() }
with h5py.File( str(featuresFn), 'r' ) as features:
    group = features['keypts']
    for key,value in group.items():
        imgId = imageBaseFn2Id[key]
        images[imgId] = ImageWKeyPts( keypts=np.array( value ), *images[imgId] )

with featureTracksPickle.open( 'rb' ) as fin:
    featureTracks = pickle.load( fin )

minAngleRad = 10. / 200. * np.pi
maxAngleRad = np.pi - minAngleRad
maxRes = 30.
def checkIntersectAngle(objPt,prcs):
    for idx,prc1 in enumerate(prcs):
        ray1 = prc1 - objPt
        ray1n = linalg.norm(ray1)
        if ray1n < 1.e-10:
            continue
        ray1 /= ray1n
        for prc2 in prcs[idx+1:]:
            ray2 = prc2 - objPt
            ray2n = linalg.norm(ray2)
            if ray2n < 1.e-10:
                continue
            ray2 /= ray2n
            angleRad = np.arccos( np.clip( ray1.dot(ray2), -1., 1. ) )
            if angleRad > minAngleRad and angleRad < maxAngleRad:
                return True
    return False

components = featureTracks.components()
robLossArg = 10.
def initTri( pickleFn, objPts ):
    objPts.clear()
    progress = Progress(len(components))
    resTooLarge = 0
    badAngles = 0
    nFailed = 0
    maxResSqr = maxRes**2
    for objPtId,features in components.items():
        with progressAfter(progress):
            obs = [ [images[feature.iImage]] + images[feature.iImage].keypts[feature.iFeature,:5].tolist() for feature in features ]
            try:
                # we init the point-to-be-triangulated at a position that may be far away from the optimum.
                # Thus, don't use Artan loss, as it practically deactivates observations with residual norms much larger than its argument.
                # That may result in the object point getting trapped at a position that is determined by only a few bad observations.
                # Use Huber loss instead, as it results in L1-weight even for observations with large residuals.
                objPt, resNormsSqr = triangulate( obs, partial(adjust.loss.Huber,robLossArg) )
            except TriFailed:
                nFailed += 1
                continue
            resOkay = resNormsSqr < maxResSqr
            if resOkay.sum() < 2:
                resTooLarge += 1
                continue
            if not checkIntersectAngle( objPt, [ ob[0].prc for ob in obs ] ):
                badAngles += 1
                continue
            objPt = ObjPt( objPt, {} )
            objPts[objPtId] = objPt
            for ob,okay in zip(obs,resOkay):
                if not okay:
                    continue
                img = ob[0]
                objPt.obs[img.id] = ob[1:]

    logger.info( "Triangulated {} objPts, {} failed, {} residuals too large, {} bad angles",
                 len(objPts), nFailed, resTooLarge, badAngles )
    
    with open( pickleFn, 'wb' ) as fout:
        pickle.dump( objPts, fout, protocol=pickle.HIGHEST_PROTOCOL )
        logger.info( 'objPts dumped to {}', pickleFn )

with ExitStack() as stack:
    pickleFn = os.path.abspath('objPts.pickle')
    objPts = {}
    stack.callback( partial( initTri, pickleFn, objPts ) )
    with suppress(OSError), \
         open( pickleFn, 'rb' ) as fin:
        objPts = pickle.load( fin )
        stack.pop_all()
        logger.info( 'objPts loaded from {}', pickleFn )

block = adjust.Problem()
loss = adjust.loss.Wrapper( robustLoss(robLossArg) )
solveOpts = adjust.Solver.Options()
solveOpts.linear_solver_ordering = adjust.ParameterBlockOrdering()    
solveOpts.linear_solver_type = adjust.LinearSolverType.SPARSE_SCHUR
# For large bundle adjustment problems (a few thousand cameras or more) use the ITERATIVE_SCHUR solver. There are a number of preconditioner choices here. SCHUR_JACOBI offers an excellent balance of speed and accuracy. 
#solveOpts.linear_solver_type = adjust.LinearSolverType.ITERATIVE_SCHUR
#solveOpts.preconditioner_type = adjust.PreconditionerType.CLUSTER_JACOBI
solveOpts.max_num_consecutive_invalid_steps = 20
solveOpts.max_num_iterations = 1000
solveOpts.function_tolerance  = 1.e-10 # terminate as soon as an iteration reduces the total cost by less than 1% of the previous total cost
solveOpts.gradient_tolerance  = 1.e-10
solveOpts.parameter_tolerance = 1.e-10

def initBlock():
    progress = Progress(len(objPts))
    for objPt in objPts.values():
        for imgId,(x,y,*data) in objPt.obs.items():
            cost = adjust.cost.PhotoTorlegard( x, y )
            cost.data = data
            img = images[imgId]
            objPt.obs[imgId] = block.AddResidualBlock(
                cost,
                loss,
                img.prc,
                img.omfika,
                img.camera.ior,
                img.camera.adp,
                objPt.arr )
        solveOpts.linear_solver_ordering.AddElementToGroup( objPt.arr, 0 )
        progress += 1

    logger.info( "Introduced {} imgObs, {} objPts", block.NumResidualBlocks(), len(objPts) )
initBlock()

def datum():
    imgIds = list(images)
    norms = np.fromiter( ( linalg.norm(img.prc) for img in images.values() ), float )
    img1 = images[ imgIds[ norms.argmin() ] ]
    img2 = images[ imgIds[ np.abs( norms - 1. ).argmin() ] ]
    scale = linalg.norm( img1.prc - img2.prc )
    assert abs( scale - 1. ) < 1.e-12
    block.SetParameterBlockConstant( img1.prc )
    block.SetParameterBlockConstant( img1.omfika )
    unitSphere = adjust.local_parameterization.UnitSphere()
    block.SetParameterization( img2.prc, unitSphere )
datum()

for camera in cameras.values():
    for par in ( camera.ior, camera.adp ):
        block.SetParameterBlockConstant( par )
        solveOpts.linear_solver_ordering.AddElementToGroup( par, 1 )
for img in images.values():
    for par in ( img.prc, img.omfika ):
        block.SetParameterBlockConstant( par )
        solveOpts.linear_solver_ordering.AddElementToGroup( par, 1 )

#@timed
def resHisto( resNormSqr, fn, maxResNorm = None, ymax=None ):
    # we better not compute the sqrt of all squared residuals, but get the histogram of the squared residuals, for the squared bin edges. Then plot the histogram with the un-squared bin edges.
    # don't choke on extreme values!
    maxResNorm = maxResNorm or np.percentile(resNormSqr,99)**.5

    pow2 = 8
    bins = np.linspace( 0, maxResNorm, 1 + 2**pow2 ) # hist will not have an item for the right-most edge, so add 1 to support downsampling by a factor of 2.
    binsSqr = bins**2
    hist,_ = np.histogram( resNormSqr, bins=binsSqr )
    bins = bins[:-1] # plt.bar(.) wants the left bin edges only for it's 'left' argument.
    # sum neighbor bin pairs until there is a meaningful count of residual norms in the maximum bin
    while pow2 >= 4 and hist.max() < 100:
        bins = bins[0::2]
        hist = hist[0::2] + hist[1::2]
        pow2 -= 1
    plt.figure('residuals'); plt.clf()
    plt.bar( left=bins, height=hist, width=bins[1]-bins[0], color='b', linewidth=0 )
    plt.ylabel('residual count', color='b')
    plt.xlabel('residual norm')
    plt.xlim( right=maxResNorm )
    nShown = hist.sum()
    if nShown < len(resNormSqr):
        prefix = '{} ({:.0%}) of '.format( nShown, nShown / len(resNormSqr) )
    else:
        prefix = 'all '

    plt.title( prefix + "{} img residual norms; max:{:.2f}".format(
                        len(resNormSqr), resNormSqr.max()**.5 ))
    if ymax is not None:
        plt.ylim(top=ymax)
    fn = '{}.png'.format(fn)
    plt.savefig( fn, bbox_inches='tight', dpi=150 )
    plt.close('residuals') #  for some reason, plt.close(fig) doesn't work 
    logger.info( 'Residual histogram plotted to "{}"', fn )

resHistoResMax = 6.
resHistoYMax = 10000

class DeacOutliers:
    def __init__( self, block, images, objPts, solveOpts ):
        self.block = block
        self.images = images
        self.objPts = objPts
        self.solveOpts = solveOpts
        self.iDeacOutliers = 0
    def __call__( self, maxRes, fn ):
        self.iDeacOutliers += 1
        for idx in count():
            summary = adjust.Solver.Summary()
            adjust.Solve(self.solveOpts, self.block, summary)
            assert adjust.isSuccess( summary.termination_type )
            logger.info('Adjusted')
            allResiduals, allResNormsSqr, nDeacImgObs, nDeacObjPts = self.deacOutliers(maxRes)
            resHisto( allResNormsSqr, '{}.{:02d} {}'.format(self.iDeacOutliers,idx,fn), resHistoResMax, resHistoYMax)

            # refSys min/max
            minObj = np.array([np.inf]*3)
            maxObj = -minObj.copy()
            for objPt in self.objPts.values():  
                np.minimum( objPt.arr, minObj, out=minObj )
                np.maximum( objPt.arr, maxObj, out=maxObj )
            logger.info( 'RefSys min/max: {}',
                         ' '.join( '{:.2f}/{:.2f}'.format(*els) for els in zip( minObj, maxObj ) ) )

            # img area ratio
            areaRatios = []
            for imgId,image in self.images.items():
                imgPts = []
                for objPt in self.objPts.values():
                    resId = objPt.obs.get(imgId)
                    if resId is not None:
                        cost = self.block.GetCostFunctionForResidualBlock( resId )
                        imgPts.append((cost.x,cost.y))
                ch = cv2.convexHull( np.array(imgPts,np.float32) ).squeeze()
                areaRatios.append( cv2.contourArea( ch ) / ( image.nCols * image.nRows ) )

            areaRatios = np.array(areaRatios)
            areaRatiosMin = areaRatios.min()
            minAt = list(self.images.values())[areaRatios.argmin()]
            bins = np.linspace(0.,1.,11)
            hist,_ = np.histogram( areaRatios, bins=bins )
            logger.info('Covered image areas\n'
                        '   {}\n'
                        '{}\n'
                        'range: [{:.0%} - {:.0%}]\n'
                        'min @ {}',
                        ''.join( '{:^7d}'.format(el) for el in hist ),
                        ''.join( '{:^7.1f}'.format(el) for el in bins ),
                        areaRatiosMin,
                        areaRatios.max(),
                        minAt.path.name )
            if  areaRatiosMin < .4:
                deacObjPts = []
                nDeacImgObs = 0
                for objPtId,objPt in self.objPts.items():
                    resId = objPt.obs.pop(minAt.id,None)
                    if resId is not None:
                        self.block.GetCostFunctionForResidualBlock( resId ).deAct()
                        nDeacImgObs += 1
                        if len(objPt.obs) < 2:
                            deacObjPts.append(objPtId)
                for objPtId in deacObjPts:
                    objPt = self.objPts.pop(objPtId)
                    self.block.SetParameterBlockConstant( objPt.arr ) 
                    for resId in objPt.obs.values():
                        self.block.GetCostFunctionForResidualBlock( resId ).deAct()
                        nDeacImgObs += 1

                image = images.pop(minAt.id)
                for par in ( image.prc, image.omfika ):
                    block.SetParameterBlockConstant( par )
                logger.info( 'Deac pho {}: Deactivated {} imgObs, {} objPts',
                             minAt.path.name, nDeacImgObs, len(deacObjPts) )

            # TODO: avoid re-adjustment just because 1 or 2 residuals are a little larger than the threshold:
            # we cut off at x, and after adjustment, it is very probable that at least one residual results as slightly larger than x, again.
            if not (nDeacImgObs + nDeacObjPts):
                break

        # list( el for objPt in self.objPts.values() for el in objPt.obs.values() )
        img = next(iter(self.images.values()))
        resX = np.ceil( img.nCols / ( img.nCols // 100 ) )
        resY = np.ceil( img.nRows / ( img.nRows // 100 ) )
        nX = int( np.ceil( img.nCols / resX ) )
        nY = int( np.ceil( img.nRows / resY ) )
        avg = np.zeros( (nY,nX,2), float )
        counts = np.zeros( (nY,nX), int )
        iRes = 0
        for objPt in self.objPts.values():
            for resId in objPt.obs.values():
                cost = self.block.GetCostFunctionForResidualBlock( resId )
                col =  cost.x // resX
                row = -cost.y // resY
                avg[row,col] += allResiduals[iRes*2 : iRes*2+2]
                counts[row,col] += 1
                iRes += 1
        avg[counts>0,0] /= counts[counts>0]
        avg[counts>0,1] /= counts[counts>0]
        gridX = np.arange(resX/2, resX*nX, resX)
        gridY = np.arange(resY/2, resY*nY, resY)
        xv, yv = np.meshgrid(gridX, gridY)
        medLen = np.median( np.sum(avg**2, axis=2 ) )**.5
        scale = 50 / medLen
        plt.figure('distortion'); plt.clf()
        plt.plot( xv, -yv, '.g' )
        plt.plot( np.c_[   xv.flat,    xv.flatten()  + scale*avg[:,:,0].flatten() ].T,
                  np.c_[ (-yv).flat, (-yv).flatten() + scale*avg[:,:,1].flatten() ].T,
                  '-r' )
        plt.ylabel('y')
        plt.xlabel('x')
        plt.xlim( 0, img.nCols )
        plt.ylim( -img.nRows, 0  )
        plt.title( "Distortion (#min/med/max={}/{}/{})".format( np.min(counts), np.median(counts), np.max(counts) ) )
        ax = plt.gca()
        ax.add_artist( AnchoredSizeBar(ax.transData, size=50*2, label='{:.2f}px'.format(medLen*2), loc=4, color='red') )
        distFn = 'distortion {} {}.png'.format(self.iDeacOutliers,fn)
        plt.savefig( distFn, bbox_inches='tight', dpi=150 )
        plt.close('distortion')
        logger.info( 'Distortion plotted to "{}"', distFn )

        export(block,images,objPts,'reconstruction {} {}'.format(self.iDeacOutliers,fn))

        camera = next(iter(cameras.values()))
        if not block.IsParameterBlockConstant(camera.ior):
            logger.info('x0\ty0\tz0\n'
                        '{}',
                        '\t'.join( '{:.2f}'.format(el) for el in camera.ior ) )
        if not block.IsParameterBlockConstant(camera.adp):
            logger.info('\t'.join( 'affSk affSc rad3 rad5 tang1 tang2 rad7 rad9 rad11'.split() ) + '\n'
                        '{}',
                        '\t'.join( '{:.2f}'.format(el) for el in camera.adp ) )
    #@timed
    def deacOutliers( self, maxRes ):
        numResidualsBefore = self.block.NumResiduals()
        maxResSqr = maxRes**2
        deacObjPts = []
        nDeacImgObs = 0
        evalOpts = adjust.Problem.EvaluateOptions()
        evalOpts.apply_loss_function = False
        evalOpts.set_residual_blocks( list( el for objPt in self.objPts.values() for el in objPt.obs.values() ) )
        allResiduals, = self.block.Evaluate( evalOpts )
        allResNormsSqr = allResiduals[0::2]**2 + allResiduals[1::2]**2
        iResNorm = 0
        Rs = { imgId : ori.omfika(img.omfika) for imgId,img in self.images.items() }
        for objPtId,objPt in self.objPts.items():
            for imgId in list(objPt.obs):
                if allResNormsSqr[iResNorm] >= maxResSqr or \
                    Rs[imgId].T.dot(objPt.arr)[2] > 0.:
                    resId = objPt.obs.pop(imgId)
                    self.block.GetCostFunctionForResidualBlock( resId ).deAct()
                    nDeacImgObs += 1
                iResNorm += 1
            if len(objPt.obs) < 2 or \
               not checkIntersectAngle( objPt.arr, [ self.images[iImg].prc for iImg in objPt.obs ] ):
                deacObjPts.append(objPtId)
        for objPtId in deacObjPts:
            objPt = self.objPts.pop(objPtId)
            self.block.SetParameterBlockConstant( objPt.arr )
            for resId in objPt.obs.values():
                self.block.GetCostFunctionForResidualBlock( resId ).deAct()
                nDeacImgObs += 1

        logger.info('Res.norm cutoff: {}. Deactivated {} imgObs, {} objPts\n'
                    'Remaining {} imgObs, {} objPts ',
                    maxRes, nDeacImgObs, len(deacObjPts),
                    sum(1 for objPt in self.objPts.values() for el in objPt.obs),
                    len(self.objPts) )
        assert numResidualsBefore - nDeacImgObs*2 == self.block.NumResiduals()

        multiplicities = np.fromiter( ( len(objPt.obs) for objPt in self.objPts.values() ), int )
        bincount = np.bincount( multiplicities, minlength=5 )
        logger.info('Views per object point\n'
                    '2\t3\t4\t5\t6\tmore\n'
                    '{}',
                    '\t'.join( '{}'.format(el) for el in (bincount[2],bincount[3],bincount[4],bincount[5],bincount[6],bincount[7:].sum()) ) )

        ptsPerImg = Counter( ( ob for objPt in self.objPts.values() for ob in objPt.obs ) )
        bins=[0,40,80,160,320,640,np.inf]
        values = np.fromiter( ptsPerImg.values(), int )
        hist,_ = np.histogram( values, bins=bins )
        logger.info('Points per image\n'
                    '     {}\n'
                    '{}\n'
                    'range: [{} - {}]',
                    ''.join( '{:^10d}'.format(el) for el in hist ),
                    ''.join( '{:^10d}'.format(el) if type(el)==int else '{:^10}'.format('inf') for el in bins ),
                    values.min(),
                    values.max() )
        return allResiduals, allResNormsSqr, nDeacImgObs, len(deacObjPts)

deacOutliers = DeacOutliers( block, images, objPts, solveOpts )
#deacOutliers( 10., 'init' )

for img in images.values():
    for par in ( img.prc, img.omfika ):
        block.SetParameterBlockVariable( par )

deacOutliers( 30., 'EORs free, {}'.format(loss) )

for camera in cameras.values():
    block.SetParameterBlockVariable( camera.ior )
    block.SetParameterBlockVariable( camera.adp )
    subSet = Subset( camera.adp.size,
                     [el for el in range(camera.adp.size)
                          if el not in (adjust.PhotoDistortion.optPolynomRadial3,) ] ) # rad5, rad7, affSk, affSc, tang1, tang2 bringen keine offensichtliche Verbesserung laut Distortion-plot.
    block.SetParameterization( camera.adp, subSet )

loss.Reset( robustLoss(5.) )
deacOutliers( 15., 'EORs, IORs, ADPs free, {}'.format(loss) )

#loss.Reset( robustLoss(3.) )
#deacOutliers( 9., 'EORs, IORs, ADPs free, {}'.format(loss) )
#
## Das Residuenhistogramm schaut eher danach aus, dass bei 4-5px abgeschnitten werden sollte.
#loss.Reset( robustLoss(2.) )
#deacOutliers( 6., 'EORs, IORs, ADPs free, {}'.format(loss) )

#loss.Reset( robustLoss(1.) )
#deacOutliers( 3., 'EORs, IORs, ADPs free, {}'.format(loss) )

#loss.Reset( adjust.loss.Trivial() )
#deacOutliers( 4., 'EORs, IORs, ADPs free, {}'.format(loss) )

saveSQLite( cameras, images, objPts, block, 'reconstruction.sqlite' )
